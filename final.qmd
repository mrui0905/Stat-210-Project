---
title: "Final Project CHANGE TITLE"
author: "Matthew Rui and Rohit Suresh"
format: pdf
---

## Load Data
```{r exercise-0, message = F, warning = F}
library(tidyverse)
library(tidymodels)

barttorvik_away <- read_csv("data/Barttorvik Away.csv")
barttorvik_home <- read_csv("data/Barttorvik Home.csv")

# Remove % from column names
colnames(barttorvik_away) <- gsub("%", "", colnames(barttorvik_away))
names(barttorvik_away) <- gsub("^([0-9])", "X\\1", names(barttorvik_away))
barttorvik_away$ROUND <- as.character(barttorvik_away$ROUND)
barttorvik_away$ROUND <- factor(barttorvik_away$ROUND, levels = c("1", "2", "4", "8", "16", "32", "64", "68", "0"))


```

## Introduction and Data
```{r intro, message = F, warning = F}
# Create a data frame
data <- data.frame(Response = barttorvik_away$ROUND, Predictor = barttorvik_away$X2PTD)

# Plotting stacked box plots
ggplot(data, aes(x = Response, y = Predictor, fill = Response)) +
  geom_boxplot() +
  labs(title = "Stacked Box Plots of Predictor vs Response",
       x = "Response", y = "Predictor") +
  theme_minimal()

library(ggplot2)
# Create heatmap
summary_data <- barttorvik_away %>%
  group_by(ROUND, `X2PT`, `X2PTD`) %>%
  summarise(mean_round = mean(as.numeric(ROUND)))

# Create heatmap
ggplot(summary_data, aes(x = `X2PT`, y = `X2PTD`, fill = mean_round)) +
  geom_tile(width = 0.4, height = 0.4) +  # Adjust width and height as needed
  scale_fill_gradient(low = "darkblue", high = "red", name = "Mean Round") +  # Adjust colors
  labs(x = "2pt", y = "2ptd", title = "Heatmap of Mean Round vs 2pt and 2ptd") +
  theme_minimal()
```


## Model
```{r model-1, message = F, warning = F}
library(nnet)
m1 <- multinom(ROUND ~ X2PT + X2PTD, data = barttorvik_away)

confint(m1)
exp(coef(m1))
```

## Model
```{r model-2, message = F, warning = F}
m2 <- lm(WIN ~ X2PT + X3PT + X2PTD + X3PTD + TOV + OREB + TOVD + DREB + PPPO, data = barttorvik_away)

summary(m2)
```

## Model
```{r model-4, message = F, warning = F}
library(glmnet)

df <- subset(barttorvik_away, select = c(ROUND, BARTHAG, GAMES, WIN, EFG, EFGD, FTR, FTRD, TOV, TOVD, OREB, DREB, `RAW T`, EXP, `ELITE SOS`, FT, `OP FT`))
df <- df %>%
  mutate(final_four = case_when(
    ROUND == 1 ~ 1,
    ROUND == 2 ~ 1,
    ROUND == 4 ~ 1,
    TRUE ~ 0
  ))
df$final_four <- as.factor(df$final_four)
df <- subset(df, select = -c(ROUND))


m3 = glm(final_four ~ ., family = "binomial", data=df)
summary(m3)

predicted_prob <- predict(m3, type = "response")

# Find the optimal threshold using ROC curve
library(pROC)
roc_obj <- roc(selected_df$final_four, predicted_prob)
optimal_threshold <- coords(roc_obj, "best", ret = "threshold")[[1]]

# Print the optimal threshold
print(paste("Optimal threshold:", optimal_threshold))

# Classify based on the optimal threshold
df$predicted_class <- ifelse(predicted_prob >= optimal_threshold, 'yes', 'no')
table(df$predicted_class, df$final_four)

```
Sensitivtiy = 43/60 = 71.7%
specif = 859/1019 = 84.3%
ppv = 43/177 = 24.3%
npv = 859/876 = 98.1%
## Model
```{r model-5, message = F, warning = F}
# Assuming your data is in a data frame called 'df'
# and the target variable is named 'target'

# Load the necessary libraries
library(caret)
library(randomForest)

# Set the number of folds for cross-validation
k_folds <- 50

# Set the number of top features to select
k_features <- 5

# Perform cross-validation with random forest
set.seed(123)  # For reproducibility
rf_cv <- train(
  x = df[, !colnames(df) %in% "final_four"],
  y = df$final_four,
  method = "rf",
  trControl = trainControl(
    method = "cv",
    number = k_folds,
    verboseIter = TRUE  # Enable progress tracking
  ),
  importance = TRUE

)

# Get the variable importance scores
var_importance <- varImp(rf_cv)

# Select the top k features based on variable importance
top_features <- rownames(var_importance$importance)[1:k_features]

# Print the top k features
print(top_features)
```

```{r model-5, message = F, warning = F}

library(caret)

# Set the number of top features to select
k_features <- 10

# Perform PCA
pca_model <- prcomp(df[, !colnames(df) %in% "final_four"], scale. = TRUE)

# Get the variable loadings (importance scores)
var_loadings <- abs(pca_model$rotation)

# Create a data frame with variable loadings and original feature names
var_loadings_df <- data.frame(var_loadings, Feature = colnames(df)[!colnames(df) %in% "final_four"])

# Melt the data frame to create a long format
var_loadings_melt <- reshape2::melt(var_loadings_df, id.vars = "Feature")

# Select the top k features based on variable loadings
top_features <- var_loadings_melt %>%
  group_by(Feature) %>%
  summarise(MaxLoading = max(value)) %>%
  top_n(k_features, MaxLoading) %>%
  pull(Feature)

# Print the top k features
print(top_features)

# Create a new data frame with selected features and the target variable
selected_df <- df[, c(top_features, "final_four")]

m6 = glm(final_four ~ BARTHAG + DREB + EXP + FT + GAMES + `OP FT` + `RAW T` +  TOV + TOVD, family = "binomial", data=selected_df)
summary(m6)

predicted_prob <- predict(m6, type = "response")

# Find the optimal threshold using ROC curve
library(pROC)
roc_obj <- roc(selected_df$final_four, predicted_prob)
optimal_threshold <- coords(roc_obj, "best", ret = "threshold")[[1]]

# Print the optimal threshold
print(paste("Optimal threshold:", optimal_threshold))

df$predicted_class <- ifelse(predicted_prob >= optimal_threshold, 'yes', 'no')
table(df$predicted_class, df$final_four)


```
same as above