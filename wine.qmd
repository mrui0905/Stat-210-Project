---
title: "Final Project"
author: "Matthew Rui and Rohit Suresh"
format: pdf
---

## Load Data
```{r Load Data, message = F, warning = F}
library(tidyverse)
library(tidymodels)
library(ggplot2)
library(pROC)
library(randomForest)
library(caret)
library(dplyr)

red <- read.csv("winequality-red.csv", sep=";")
red$color <- "red"
white <- read.csv("winequality-white.csv", sep=";")
white$color <- "white"

df <- rbind(red, white)
df <- na.omit(df)
df$quality <- as.factor(df$quality)
```

## Introduction and data

Wine quality evaluations play an important role in numerous parts of the wine supply chain. They are important for quality assurance, market differentiation, and consumer guidance. Generally, a wine quality evaluation analyzes appearance, aroma, flavor, structure, and overall balance to generate a score from 1 to 10. Physicochemical properties of wine samples is readily available to most manufacturers, and quantifying the relationship between physiochemical properties and wine quality evaluations could be of great interest to manufacturers. It may help them with quality control, product development, and cost efficiency. [ADD CITATION]

The data for this work is from the UC Irvine Machine Learning Repository from the paper Cortez et al., 2009. [ADD CITATION] Rows with missing data were removed and quality was treated as a factor. 

Datasets for white wine and red wine were provided separately from the source. In this work, we combined the data into one dataset, creating a new variable for the color of wine (color) in the process. [DEFINE VARIABLES]


```{r intro-0, message = F, warning = F}
summary(df)
```

Red wines, on average, have lower quality scores than white wines on average. While this will result in a more complex model, it will more accurately picture the data in one model, which is why we chose to do this.

```{r intro-1, message = F, warning = F}
# Create a bar plot of quality
barplot_quality <- ggplot(df, aes(x = factor(quality))) +
  geom_bar(fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "Bar Plot of Wine Quality", x = "Quality", y = "Frequency") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Plot the bar plot
print(barplot_quality)
```

To perform logistic regression, a quality threshold for high quality vs low quality was established after analyzing the distribution of quality scores. 



Samples with quality scores of 7 or greater were classified as high quality. [ADD REASONING]

``` {r intro-2, message = F, warning = F}
# Continuing, let's try to predict whether a wine is high quality (>= 7).
df$high_quality <- ifelse(df$quality %in% c("7", "8", "9"), 1, 0)

df$high_quality <- factor(df$high_quality, levels = c(0, 1), labels = c("No", "Yes"))
```

Alcohol could be a good predictor of whether a wine is high quality.

``` {r intro-3, message = F, warning = F}
# Create a box plot of alcohol and high_quality
boxplot_sulphates <- ggplot(df, aes(x = high_quality, y = alcohol, fill = high_quality)) +
  geom_boxplot() +
  labs(title = "Box Plot of Alcohol and High Quality", x = "High Quality", y = "Alcohol") +
  scale_fill_manual(values = c("No" = "skyblue", "Yes" = "pink")) +  # Custom colors for the fill
  theme_minimal()

# Plot the box plot
print(boxplot_sulphates)
```

## Linear Regression
```{r Linear Regression, message = F, warning = F}

# Can we predict alcohol levels?

# Simple Linear Regression
simple_linear_regression <- lm(alcohol ~ ., data=df)
summary(simple_linear_regression)

# Residual Plot + Q-Q + Histogram

simple_linear_regression_aug <- augment(simple_linear_regression)
ggplot(simple_linear_regression_aug, aes(x = .fitted, y = .resid)) + 
  geom_point() + 
  geom_hline(yintercept = 0, color = "darkred") + 
  labs(x = "Fitted alcohol value", y = "Residual") + 
  theme_bw()

ggplot(simple_linear_regression_aug, aes(sample = .resid)) +
  stat_qq() + 
  stat_qq_line() + 
  theme_bw() + 
  labs(x = "Theoretical quantiles", 
       y = "Sample quantiles")

ggplot(simple_linear_regression_aug, aes(x = .resid)) + 
  geom_histogram(aes(y = ..density..), 
                     fill = "deepskyblue", color = "darkblue") + 
  stat_function(fun = dnorm, 
                args = list(mean = mean(simple_linear_regression_aug$.resid),
                            sd = sd(simple_linear_regression_aug$.resid)),
                color = "darkred", lwd = 2) +
  labs(x = "Residual", y = "Density") + 
  theme_bw()

# We have 1 clear outlier - what happens if we remove it?
residuals <- residuals(simple_linear_regression)
outliers <- df[abs(residuals) > 10, ]

df <- df[abs(residuals) <= 10, ]

simple_linear_regression_pruned <- lm(alcohol ~ ., data=df)
summary(simple_linear_regression_pruned)

simple_linear_regression_pruned_aug <- augment(simple_linear_regression_pruned)
ggplot(simple_linear_regression_pruned_aug, aes(x = .fitted, y = .resid)) +
  geom_point(color = "darkblue", size = 2) +
  geom_hline(yintercept = 0, color = "darkred", linetype = "dashed", size = 1) +
  labs(x = "Fitted Alcohol Value (ABV)", y = "Residuals", title = "Linearity and Homoscedasticity Assumptions are Satisfied") +
  theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "black", fill = NA, size = 1),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    plot.title = element_text(size = 13, face = "bold", hjust = 0.5)
  )


ggplot(simple_linear_regression_pruned_aug, aes(sample = .resid)) +
  stat_qq(color = "darkblue", size = 1) +
  stat_qq_line(color = "darkred", linetype = "dashed", size = 1) +
  theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "black", fill = NA, size = 1),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5)
  ) +
  labs(x = "Theoretical Quantiles",
       y = "Sample Quantiles",
       title = "Normality Assumption is Satisifed")

ggplot(simple_linear_regression_pruned_aug, aes(x = .resid)) +
  geom_histogram(aes(y = ..density..),
                 fill = "deepskyblue", color = "darkblue", bins = 30) +
  stat_function(fun = dnorm,
                args = list(mean = mean(simple_linear_regression_pruned_aug$.resid),
                            sd = sd(simple_linear_regression_pruned_aug$.resid)),
                color = "darkred", size = 1) +
  labs(x = "Residual", y = "Density", title = "Histogram of Residuals") +
  theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "black", fill = NA, size = 1),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5)
  )


# Ok, now what if we add interaction terms for color of wine?
linear_regression_interaction <- lm(alcohol ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + quality + color + color*fixed.acidity + color*volatile.acidity + color*citric.acid + color*residual.sugar + color*chlorides + color*free.sulfur.dioxide + color*total.sulfur.dioxide + color*density + color*pH + color*sulphates + color*quality, data=df)
summary(linear_regression_interaction)

# Note that p > n for quality = 9 and color = white, hence we're unable to obtain estimates.

# Residual Plot + Q-Q + Histogram Again
linear_regression_interaction_aug <- augment(linear_regression_interaction)

ggplot(linear_regression_interaction_aug, aes(x = .fitted, y = .resid)) +
  geom_point(color = "darkblue", size = 2) +
  geom_hline(yintercept = 0, color = "darkred", linetype = "dashed", size = 1) +
  labs(x = "Fitted Alcohol Value (ABV)", y = "Residuals", title = "Linearity and Homoscedasticity Assumptions are Satisfied") +
  theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "black", fill = NA, size = 1),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    plot.title = element_text(size = 13, face = "bold", hjust = 0.5)
  )

ggplot(linear_regression_interaction_aug, aes(sample = .resid)) +
  stat_qq(color = "darkblue", size = 1) +
  stat_qq_line(color = "darkred", linetype = "dashed", size = 1) +
  theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "black", fill = NA, size = 1),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5)
  ) +
  labs(x = "Theoretical Quantiles",
       y = "Sample Quantiles",
       title = "Normality Assumption is Satisifed")

ggplot(linear_regression_interaction_aug, aes(x = .resid)) +
  geom_histogram(aes(y = ..density..),
                 fill = "deepskyblue", color = "darkblue", bins = 30) +
  stat_function(fun = dnorm,
                args = list(mean = mean(linear_regression_interaction_aug$.resid),
                            sd = sd(linear_regression_interaction_aug$.resid)),
                color = "darkred", size = 1) +
  labs(x = "Residual", y = "Density", title = "Histogram of Residuals") +
  theme_minimal() +
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "black", fill = NA, size = 1),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5)
  )
```

## Classification w/ Logistic
```{r Logistic Regression, message = F, warning = F}

# Continuing, let's try to predict whether a wine is high quality (>= 7, arbitrary cutoff).
df$high_quality <- ifelse(df$quality %in% c("7", "8", "9"), 1, 0)

logistic_model <- glm(high_quality ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol + color, data=df, family="binomial")
summary(logistic_model)

# Honestly pretty good, let's now try again with interaction terms

logistic_model_interaction <- glm(high_quality ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol + color + color*fixed.acidity + color*volatile.acidity + color*citric.acid + color*residual.sugar + color*chlorides + color*free.sulfur.dioxide + color*total.sulfur.dioxide + color*density + color*pH + color*sulphates + color*alcohol, data=df, family="binomial")
summary(logistic_model_interaction)

# Surprisingly, some of the predictor which were significant for the model w/o interaction terms are no longer significant. Let's see which model is a better classifier then.

prob_logistic <- predict(logistic_model, type = "response")
roc_logistic <- roc(df$high_quality, prob_logistic)
optimal_logistic <- coords(roc_logistic, "best", ret = "threshold")[[1]]
print(paste("Optimal threshold:", optimal_logistic))
optimal_threshold <- 0.5
df$predict_logistic <- ifelse(prob_logistic >= optimal_threshold, 'High Quality', 'Low Quality')
table(df$predict_logistic, df$high_quality)

prob_logistic_interaction <- predict(logistic_model_interaction, type = "response")
roc_logistic_interaction <- roc(df$high_quality, prob_logistic_interaction)
optimal_logistic_interaction <- coords(roc_logistic_interaction, "best", ret = "threshold")[[1]]
print(paste("Optimal threshold:", optimal_logistic_interaction))
df$predict_logistic_interaction <- ifelse(prob_logistic_interaction >= optimal_threshold, 'High Quality', 'Low Quality')
table(df$predict_logistic_interaction, df$high_quality)

```
Logistic Model:
- Sensitivity: 1183/(1183+94) = 0.9263899765
- Specificity: 2050/(2050+3169) = 0.3927955547
- Positive Predictive Value: 1183/(1183+3169) = 0.27182904411
- Negative Predictive Value: 2050/(2050+94) = 0.95615671641

Logistic Interaction Model:
- Sensitivity: 1203/(1203+74) = 0.94205168363
- Specificity: 2091/(2091+3128) = 0.40065146579
- Positive Predictive Value: 1203/(1203+3128) = 0.27776495035
- Negative Predictive Value: 2091/(2091+74) = 0.96581986143

The interaction model is better in every metric!

## Random Forest

```{r Random Forest, message=FALSE, warning=FALSE}

include_cols <- c('fixed.acidity' , 'volatile.acidity' , 'citric.acid' , 'residual.sugar' , 'chlorides' , 'free.sulfur.dioxide' , 'total.sulfur.dioxide' , 'density' , 'pH' , 'sulphates' , 'alcohol' , 'color')
X <- df[, (names(df) %in% include_cols)]  
y <- df$high_quality
k <- 10
ctrl <- trainControl(method = "cv", number = k, verboseIter = TRUE)
rf_model <- train(x = X, y = y, method = "rf", trControl = ctrl)

print(rf_model)
df$rf_predictions <- predict(rf_model, X)
df$rf_classification <- ifelse(df$rf_predictions > 0.5, "High Quality", "Low Quality")

table(df$rf_classification, df$high_quality)

red <- read.csv("winequality-red.csv", sep=";")
red$color <- "red"
white <- read.csv("winequality-white.csv", sep=";")
white$color <- "white"

df <- rbind(red, white)
df <- na.omit(df)

X <- df[, (names(df) %in% include_cols)]  
y <- df$quality
k <- 10
ctrl <- trainControl(method = "cv", number = k, verboseIter = TRUE)
rf_model_general <- train(x = X, y = y, method = "rf", trControl = ctrl)

print(rf_model_general)
df$rf_predictions_general <- predict(rf_model_general, X)
df$rf_classification_general <- round(df$rf_predictions_general)

accuracy_by_outcome <- df %>%
  group_by(quality) %>%
  summarise(accuracy = mean(quality == rf_classification_general))

overall_accuracy <- mean(df$quality == df$rf_classification_general)

print(accuracy_by_outcome)
cat("Overall Prediction Rate:", overall_accuracy, "\n")
```
Random Forest Model:
- Sensitivity: 1262/(1262+15) = 0.98825371965
- Specificity: 5219/(5219+0) = 1
- Positive Predictive Value: 1262/(1262+0) = 1
- Negative Predictive Value: 5219/(5219+15) = 0.99713412304
